%!TEX root = ../thesis.tex

\chapter{High level trigger development for Top Physics}
\label{c:service_work}
\ifpdf
    \graphicspath{{04_Service_work/plots/}}
\else
    \graphicspath{{04_Service_work/plots/EPS/}{04_Service_work/plots/}}
\fi

The LHC is often referred to as a top quark factory, producing a \ttbar pair nearly each second of its nominal
operation. While the production rate of \SI{\approx1}{\Hz} seems manageable in terms of recording the data, it is
significantly complicated by background processes with similar signatures occurring at much higher rates.

The trigger is the starting point of any physics event selection process, and therefore is clearly important for any
physics analysis. As it was mentioned in Section~\ref{ss:trigger_daq}, the CMS L1 trigger rate is limited to
\SI{\sim100}{\kilo\hertz}. In order to meet the data recording constraints of approximately
\SI{300}{\mega\byte\per\second}, this rate is further reduced down to \SI{\sim300}{\Hz}, which is done by the HLT
system. The total rate budget has to be shared between various physics analysis groups (e.g.\ Top, Higgs, Exotica,
etc.). Corresponding allocations are determined by CMS trigger coordination according to CMS physics goals, and can be a
matter of serious debate.

During the LHC operation in 2011 and 2012 under conditions of gradual increase of instantaneous luminosity and pile-up,
but very limited rate budget, trigger developers constantly tackled the challenge of finding the best compromise between
growing rates and maintaining reasonable signal acceptance. While the simplest approach is tightening the cuts on
physical quantities like lepton or jet transverse momenta, it is not favourable since it lowers the number of stored
signal events and decreases the phase space which is crucial for new physics searches as well as Standard Model
precision measurements. Therefore, development of more efficient algorithms allowing to keep high level of acceptance
for signal events, whilst effectively rejecting background events, is the most preferable solution. This can often be
achieved by increasing the level of approximation of the online (HLT) object reconstruction, making the algorithms
closer to their sophisticated offline counterparts. However, it leads to a higher execution time, which is limited by
computing resources available for HLT reconstruction. Hence, the CPU timing is another major constraint faced by the HLT
developers.

This chapter covers my contribution to development and verification of High-Level Triggers for top physics with
semileptonic signature, where one of the W bosons decays into an electron and a neutrino. Trigger efficiency
measurement, CPU timing studies, validation of jet energy corrections and pile-up subtraction applied at the HLT level
are discussed in relevant sections of this chapter.

\section{Level-1 triggers}
The L1 trigger budget of \SI{\sim100}{\kilo\hertz} is shared between several L1 trigger ``seeds'', corresponding to
different physics objects being present in the event. For top physics with a single electron in the final state, the
following L1 seeds are used: L1\_SingleEG\_18, L1\_SingleEG\_20 and L1\_SingleEG\_22.

%mention L1_SingleEG_18, L1_SingleEG_20 and L1_SingleEG_22 paths, 4x4 ECAL crystal cells

The L1 trigger decisions are used as an input to the HLT system, described in the following section.

\clearpage

\section{High-level triggers for top physics}
%(perhaps) a separate section? the model of trigger trains, lumi history, etc

The High-Level Trigger \cite{HLT} is the crucial part of CMS event selection process. As it was mentioned in
Section~\ref{ss:trigger_daq}, it is based on software algorithms running on the Event Filter Farm, i.e.\ a large cluster
of commercial CPUs. The HLT reconstruction, often referred to as online reconstruction, is implemented in the same
software framework (CMSSW) which is used for offline reconstruction, and the algorithms can be very similar. However,
the key difference between online and offline reconstruction is the running time. Since the HLT selection has to be
performed in real time, it imposes a significant constraint on computing resources, enforcing to compromise on
robustness and efficiency of online algorithms. With an exception of small samples for performance monitoring, data
rejected by the HLT is lost irrevocably. Therefore, correct and efficient operation of the HLT is of major importance
for CMS physics programme.

Modular structure of CMSSW provides high flexibility in use of selection and reconstruction algorithms, allowing their
continuous optimisation according to changes in physics needs and data-taking conditions. Various modules account for
reconstruction of different physics objects and their matching with L1 objects, filtering, logging, monitoring, etc. All
these modules are grouped into so-called trigger ``paths'', ultimately giving trigger decisions on whether to accept an
event or not. A typical example of a trigger path used for top physics is an electron-plus-jets trigger, which requires
the presence of isolated electron and at least three energetic jets in the event.

There are two types of trigger paths: prescaled and unprescaled. Prescaling is a method of reducing the trigger rate by
only recording a fraction of events that pass the trigger selection. For example, if the prescale value of a particular
trigger is 10, only one out of ten events that fire the trigger will be actually recorded. Usually prescaled triggers
are used for backrground estimation as they can impose a much looser selection criteria yet still have manageable rate.
However, such triggers are unfavourable for signal selection, as they greatly reduce signal acceptance.

A set of trigger paths and their prescale factors is combined in the HLT configuration, referred to as the HLT menu or
table \cite{HLT_commissioning}. Since the start of data-taking in 2010, the CMS trigger coordination adopted a ``trigger
train'' model, implying the schedule of regular deadlines for updates in the trigger menu. These deadlines are usually
imposed according to changes in instantaneous luminosity or other alterations in data-taking conditions. In order for a
trigger path to be included in the trigger menu, it has to be implemented in the HLT configurations database, validated
by measuring the trigger rate and signal efficiency, tested for CPU timing and finally approved by the trigger studies
group.

As it was mentioned before, the top quark pair decay covered in this work has a semileptonic signature, containing an
electron, at least four jets and a neutrino in form of \MET. Due to the nature of the decay, all these objects are
highly energetic and can be triggered on with rather high thresholds on transverse energy. During the start-up year of
2010 when the instantaneous luminosity went up from \SI{\sim d27}{\cm^{-2} s^{-1}} to \SI{\sim d31}{\cm^{-2} s^{-1}},
top analyses with the signature of interest used the single electron trigger, requiring just one electron with certain
isolation and transverse momentum criteria. However, by extrapolating the trigger rates on higher luminosities foreseen
in the following years it became obvious that the single electron trigger rate would quickly become too high for the
rate budget restrictions at the time. Therefore, alternative ways of adding other objects from the \ttbar signature were
explored, naturally leading to electron-plus-jets trigger solution.

A typical electron-plus-jets trigger consists of a standard electron module, a jet module, a cleaning module to remove
overlap between jet and electron collections, and a jet multiplicity filter. The electron module is constructed from the
following sub-modules:

\begin{itemize}
  \item L1 object and ECAL super-cluster matching;
  \item ECAL transverse energy filter;
  \item ECAL electron ID and isolation filter;
  \item HCAL electron ID and isolation filter;
  \item tracker electron ID and isolation filter.
\end{itemize}

To minimise the total running time, all the sub-modules are ordered by speed, starting from the fastest. The matching
module finds the ECAL super-cluster closest to the L1 object in $\eta$ and $\phi$ dimensions. If the super-cluster is
located within a certain $\eta$ and $\phi$ range, the event is passed to the next module, otherwise it is rejected.

The following (ECAL) module calculates the super-cluster transverse energy ($E_\mathrm{T}$), and in case if it is above
\SI{25}{\GeV}, the electron ID and isolation criteria are imposed for both ECAL and HCAL (see
Section~\ref{ss:electron_reconstruction}). The working points of identification and isolation and their naming
conventions are shown in Table~\ref{tab:trigger_naming}.

\input{04_Service_work/tables/trigger_naming}
% source: https://twiki.cern.ch/twiki/bin/view/CMS/EgammaWorkingPointsv3 (restricted access so no reference)
% although, can reference Luke's thesis

In the main trigger path used for signal rather than background estimation, Very Tight (VT) working point for
calorimeter identification (CaloID) and Tight (T) working point for calorimeter isolation (CaloIso) were used. This was
motivated by consistency with similar criteria for the single electron trigger used in 2010.

For the events that pass all described criteria in the electron module, a simplified algorithm for offline iterative
tracking is applied. This algorithm has a faster running time at the expense of worse resolution. In order to decrease
the CPU usage, the Combinatorial Track Finder (CTF) \cite{CTF_tracking} is used instead of the GSF one, and the tracking
is confined to a small region around the electron. The events are required to pass the tight criteria of the tracker
electron ID (TrkId) which is calculated at this stage. Finally, the tight working point of the tracker isolation
(TrkIso) is applied, where the track \pt is summed over all tracks within $\Delta R = 0.3$ cone around the electron
track, excluding the electron itself. Provided that event passes all the electron sub-modules, the jet module is then
executed.

The jet reconstruction is performed with the \antikt algorithm (see Section~\ref{ss:jet_reconstruction}) with a radius
parameter of $R = 0.5$. Historically, at the early stages of LHC operation, CMS analyses mostly used calorimeter jets,
i.e.\ jets reconstructed using calorimeter information exclusively. Therefore, initially the trigger jet module used
calorimeter jet collection, which provided fast reconstruction yet worse resolution hence lower trigger efficiency
comparing to PF jets which were introduced later on during 2011 data-taking. In order to work online, PF jet
reconstruction was modified to be compatible with the simplified tracking algorithm. Despite the fact that running the
jet module with PF jet reconstruction is highly CPU-intensive and therefore can not be used as an unprescaled
stand-alone trigger, it works effectively together with the electron module since it reduces the input event rate
considerably. Both calorimeter and PF jet versions of the module impose the $\SI{30}{\GeV}$ cut on transverse momentum
on the jets as well as the pseudorapidity cut of $|\eta| < 2.6$. Subsequently, the jet collection is passed to the
cleaning module.

Within CMS, electron and jet collections are reconstructed independently, and since they often leave similar footprints
in the detector, these collections can overlap, causing potential double-counting. The electron-jet cleaning module
removes electron candidates found by the electron module from the collection of jet candidates found by the jet module.
A jet is removed from the jet collection if there is an electron within a cone of $\Delta R = 0.3$ around the jet axis.
However, occasionally a genuine jet can be incorrectly identified as an electron. In this case the fake electron can be
removed from the jet collection, biasing the performance of the jet multiplicity filter. To tackle this issue, separate
jet collections are created for all electrons in the event, where jets are only cleaned from additional (non-signal)
electrons. All these jet collections are passed to the following jet multiplicity filter, which accepts and event if at
least one collection contains a desired number of cleaned jets.

Electron-plus-jets triggers successfully functioned throughout 2011 and 2012 years of data taking. During 2011, they
were used in the top mass analysis and differential cross section analysis with respect to missing transverse energy,
described in this thesis. The 2012 cross section analysis used a single electron trigger with a lepton \pt threshold of
\SI{27}{\GeV}, reasonably tight lepton isolation requirements, but no specific jet requirements. In contrast to 2011
running, this trigger was decided to be unprescaled in the trigger menu for the whole period of data-taking in 2012,
regardless of having a significant rate. It is favourable for many analyses as it is much more straightforward in terms
of calculating efficiency and acceptance scale factors, also reducing the complexity of estimating the systematic errors
associated with the triggering.

\section{Trigger efficiency measurement}
One of the most important characteristics of a trigger path is its efficiency. In a broad sense, selection efficiency
can be defined as a conditional probability that a single event passes the selection, given all other conditions
(detector configuration, preselection, etc) \cite{selection_efficiency}. In the context of the trigger, efficiency
highly depends on the offline selection it is measured with respect to. As a matter of fact, different studies can apply
different offline selections, therefore the same trigger may have different efficiencies for each of them.

The trigger efficiency can be measured in both data and Monte Carlo simulation using various methods. For all of them,
the study has to be performed on some initial preselected dataset. Ideally, this preselection needs to be unbiased with
respect to selection imposed by the trigger and offline selection. However, in reality it implies running on vast
amounts of data, with very little number of events satisfying the trigger selection, leading to insufficient statistics
or non-feasible computing resources needed for the study. Therefore, some other trigger is used for preselecting the
initial dataset, somewhat correlated to the trigger under study in order to obtain reasonable statistics. To correctly
measure the efficiency of a trigger path, this correlation has to be taken into account.

The efficiency of a trigger $A$ can be written as the following conditional probability:
\begin{equation}
\epsilon_{A} = P(A | \vec{x}, T, D)
\end{equation}
where $\vec{x}$ are reference quantities used for triggering (e.g.\ lepton \pt), and $T$ is an offline selection, and
$D$ is a combination of all other factors like detector effects. Assuming that these factors, along with the offline
selection and quantities used for triggering are fixed, we can denote $\epsilon_{A} = P(A)$ for brevity.

If $B$ is the trigger used for preselection, then
\begin{equation}
P(A, B) = P(A | B) \cdot P(B) = P(B | A) \cdot P(A)
\end{equation}

Therefore, as it immediately follows from Bayes' theorem,
\begin{equation}
P(A) = \frac{P(A | B) \cdot P(B)}{P(B | A)}
\end{equation}

Here the conditional probability $P(A|B)$ can be estimated by taking the ratio of the numbers of events that pass the
triggers $A$ and $B$, given that they all pass offline selection. Efficiency of the auxiliary trigger $\epsilon_{B} =
P(B)$ can be estimated from data by using a dataset obtained with looser (``minimum bias'') selection. Unfortunately,
conditional probability $P(B|A)$ can not be measured using real data, as by the nature of the study the trigger $A$ only
considers events preselected by the trigger $B$. However, the trigger $B$ is usually chosen such that it is safe to
assume that $P(B|A) = 1$ with negligible uncertainty. This is the case if the preselection trigger criteria are
considerably looser than those of the trigger under study. To summarise, the trigger efficiency can be measured as:

\begin{equation}
\epsilon_{A} = P(A|B) \cdot P(B) = \frac{N_A}{N_B} \cdot \epsilon_{B}
\end{equation}
where $N_{A (B)}$ is the number of events that pass the offline selection and fire the trigger $A$ ($B$).


In case of electron plus jets triggers, the efficiency can be factorised in contributions of leptonic and hadronic parts
of the trigger:
\begin{equation}
\epsilon_{ele+jets} = \epsilon_{ele} \cdot \epsilon_{jets}
\end{equation}
This method can be used under assumption that the probability of finding an electron in the event is independent of the
presence of the jets in the event, i.e. leptonic and hadronic ``legs'' of the trigger are uncorrelated. Although
such correlations do exist, it has been shown that most of them are negligible and factorisation method provides a
meaningful estimate of the trigger efficiency \cite{d0_note_top_trigger_efficiency}.

In this study, an impact of jet energy corrections and pile-up subtraction on the electron-plus-jets trigger efficiency
was investigated. Since only hadronic part of the trigger was of interest, the efficiency was measured by using a
``Single Electron'' primary dataset of raw 2012 data. This primary dataset is constructed by accepting events passing at
least one of the several single electron triggers with various \pt and isolation requirements. One of the loosest
triggers, referred to as HLT\_Ele27\_WP80, operates with working point ``WP80'' shown in Table~\ref{tab:trigger_naming},
and electron \pt threshold of \SI{27}{\GeV}.

Offline selection used to obtain the clean \ttbar sample is outlined in Section~\cite{ss:event_selection}, with an
exception of the jet multiplicity requirement: here at least three jets are required. The trigger efficiency is then
calculated as:
\begin{equation}
\epsilon = \frac{N_{\text{fired}}}{N_{\text{selected}}}
\end{equation}
where $N_{\text{selected}}$ is the number of events from the primary dataset passing the described offline selection,
and $N_{\text{fired}}$ is the number of events which in addition fired the electron plus three jet trigger.

All the efficiencies are measured in bins of jet \pt and $\eta$.

%scale factors

%Thresholds close to analysis cuts will bias distributions - must account for this

\section{Validation of jet energy corrections for top triggers}
%a bit of history

%show turn-ons and response plots

%conclusions of the study - dropping down the threshold for the 3rd jets

\section{CPU timing studies}
%decent plots would be hard to reproduce

\section{Summary}


% ------------------------------------------------------------------------


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
